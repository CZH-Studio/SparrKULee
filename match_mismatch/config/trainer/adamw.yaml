optimizer:
  name: AdamW
  params:
    lr: 0.001
    weight_decay: 0.01
    betas: [0.9, 0.999]
scheduler:
  name: StepLR
  params:
    step_size: 10
    gamma: 0.1
early_stopping:
  patience: 10
  min_delta: 0.001
trainer:
  max_epochs: 500
  accelerator: gpu
  devices: auto
  strategy: ddp
  precision: 32
